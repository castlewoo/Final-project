{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4545a1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from PIL import Image\n",
    "# def is_image_file(file_path):\n",
    "#     try:\n",
    "#         img = Image.open(file_path)\n",
    "#         img.close()\n",
    "#         return True\n",
    "#     except Exception as e:\n",
    "#         return False\n",
    "# def delete_non_image_files(folder_path):\n",
    "#     for root, dirs, files in os.walk(folder_path):\n",
    "#         for file in files:\n",
    "#             file_path = os.path.join(root, file)\n",
    "#             if not is_image_file(file_path):\n",
    "#                 os.remove(file_path)\n",
    "#                 print(f\"Deleted: {file_path}\")\n",
    "# dataset_dir = './data/dataset/all_images2'\n",
    "# class_names = os.listdir(dataset_dir)\n",
    "# # 비 이미지 파일 삭제\n",
    "# for _ in dataset_dir:\n",
    "#     dir = dataset_dir+_\n",
    "#     delete_non_image_files(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e04b4bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c78d67ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 디렉토리 설정\n",
    "dataset_dir = './data/dataset/all_images/'\n",
    "train_dir = './data/dataset/train/'\n",
    "test_dir = './data/dataset/test/'\n",
    "validation_dir = './data/dataset/validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eeebd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['간장게장',\n",
       " '갈비찜',\n",
       " '갈비탕',\n",
       " '감자전',\n",
       " '감자탕',\n",
       " '곱창구이',\n",
       " '김밥',\n",
       " '김치전',\n",
       " '김치찌개',\n",
       " '닭갈비',\n",
       " '닭볶음탕',\n",
       " '도토리묵',\n",
       " '된장찌개',\n",
       " '떡볶이',\n",
       " '막국수',\n",
       " '물냉면',\n",
       " '물회',\n",
       " '미역국',\n",
       " '배추김치',\n",
       " '불고기',\n",
       " '비빔냉면',\n",
       " '비빔밥',\n",
       " '삼겹살',\n",
       " '삼계탕',\n",
       " '설렁탕',\n",
       " '순대',\n",
       " '순두부찌개',\n",
       " '양념게장',\n",
       " '양념치킨',\n",
       " '육회',\n",
       " '잡채',\n",
       " '제육볶음',\n",
       " '족발',\n",
       " '주꾸미볶음',\n",
       " '짜장면',\n",
       " '칼국수',\n",
       " '파전',\n",
       " '해물찜',\n",
       " '황태구이',\n",
       " '후라이드치킨']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스별 이미지 파일 수를 정의\n",
    "class_names = os.listdir(dataset_dir)\n",
    "print(len(class_names))\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccad236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련, 검증, 테스트 데이터셋을 저장할 디렉토리를 생성합니다.\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "os.makedirs(validation_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62104706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 분리가 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 각 클래스마다 훈련, 검증, 테스트 데이터를 나눕니다.\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(dataset_dir, class_name)\n",
    "    train_class_dir = os.path.join(train_dir, class_name)\n",
    "    test_class_dir = os.path.join(test_dir, class_name)\n",
    "    validation_class_dir = os.path.join(validation_dir, class_name)\n",
    "    \n",
    "    os.makedirs(train_class_dir, exist_ok=True)\n",
    "    os.makedirs(test_class_dir, exist_ok=True)\n",
    "    os.makedirs(validation_class_dir, exist_ok=True)\n",
    "    \n",
    "    # 해당 클래스의 모든 이미지 파일을 리스트로 가져옵니다.\n",
    "    all_images = os.listdir(class_dir)\n",
    "    \n",
    "    # 데이터셋을 훈련, 테스트, 검증 데이터로 나눕니다.\n",
    "    train_images, test_images = train_test_split(all_images, test_size=0.2, random_state=42)\n",
    "    test_images, validation_images = train_test_split(test_images, test_size=0.5, random_state=42)\n",
    "    \n",
    "    # 훈련 데이터 복사\n",
    "    for img in train_images:\n",
    "        src_path = os.path.join(class_dir, img)\n",
    "        dest_path = os.path.join(train_class_dir, img)\n",
    "        copyfile(src_path, dest_path)\n",
    "    \n",
    "    # 테스트 데이터 복사\n",
    "    for img in test_images:\n",
    "        src_path = os.path.join(class_dir, img)\n",
    "        dest_path = os.path.join(test_class_dir, img)\n",
    "        copyfile(src_path, dest_path)\n",
    "    \n",
    "    # 검증 데이터 복사\n",
    "    for img in validation_images:\n",
    "        src_path = os.path.join(class_dir, img)\n",
    "        dest_path = os.path.join(validation_class_dir, img)\n",
    "        copyfile(src_path, dest_path)\n",
    "\n",
    "print(\"데이터셋 분리가 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a0ce809",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 사용할 모델 라이브러리 import\n",
    "import sys, os\n",
    "from keras.models import Sequential # 모델 구조를 생성하는 라이브러리\n",
    "from keras.layers import Convolution2D # 합성곱층을 생성하는 라이브러리(2차원 처리)\n",
    "from keras.layers import MaxPooling2D # 합성곱층에서 생성된 특성맵을 단순화하는 층(2차원처리)\n",
    "from keras.layers import Activation # 활성화함수 지정\n",
    "from keras.layers import Dropout # 규제적용 층\n",
    "from keras.layers import Flatten # 데이터를 1차원으로 변환시켜주는 층\n",
    "from keras.layers import Dense # 밀집층\n",
    "from keras.utils import np_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72ac828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a7a3a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "# 검증, 테스트 데이터는 증강 사용하지 않음\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale= 1./255) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49f43361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증, 테스트 데이터는 증강 사용하지 않음\n",
    "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_datagen = ImageDataGenerator(rescale= 1./255) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dbdca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 이미지 증식 generator 생성\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7cf4800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31995 images belonging to 40 classes.\n",
      "Found 4017 images belonging to 40 classes.\n",
      "Found 3994 images belonging to 40 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 16, # gpu 연산 -> 2의 거듭제곱꼴로 맞추는 것이 좋다고 함\n",
    "    seed = 42,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 16, # gpu 연산 -> 2의 거듭제곱꼴로 맞추는 것이 좋다고 함\n",
    "    seed = 42,\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 16, # gpu 연산 -> 2의 거듭제곱꼴로 맞추는 것이 좋다고 함\n",
    "    seed = 42,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a958036",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # 입력 크기는 원하는 이미지(224x224, 3채널)와 맞아야 합니다.\n",
    "    # 첫 번째 합성곱 층\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', \n",
    "                            input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    # 두 번째 합성곱 층\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    # 네 번째 합성곱 층\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    # 밀집 층에 전달하가 위해 펼칩니다.\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 512개 뉴런을 가진 은닉층\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(class_names), activation='softmax')\n",
    "    # 출력층(다중분류이므로 softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c066a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51439fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 : model 디렉터리 생성\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "import os\n",
    "\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "\n",
    "# model 안에 파일로 저장\n",
    "modelpath=\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "# EarlyStopping : 모델 최적화 단계에서 학습 자동 중단 설정  \n",
    "checkpointer = ModelCheckpoint(filepath = modelpath,\n",
    "                              monitor = 'val_loss',\n",
    "                              verbose = 1,\n",
    "                              save_best_only = True),\n",
    "early_stopping_clbk = EarlyStopping(monitor = 'val_loss', patience = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eed2036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  86/2000 [>.............................] - ETA: 3:23 - loss: 3.9141 - accuracy: 0.0349"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\tf\\lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - ETA: 0s - loss: 2.7634 - accuracy: 0.2292\n",
      "Epoch 1: val_loss improved from inf to 2.41492, saving model to ./model\\01-2.4149.hdf5\n",
      "2000/2000 [==============================] - 267s 127ms/step - loss: 2.7634 - accuracy: 0.2292 - val_loss: 2.4149 - val_accuracy: 0.3159\n",
      "Epoch 2/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 2.0386 - accuracy: 0.4165\n",
      "Epoch 2: val_loss improved from 2.41492 to 2.23843, saving model to ./model\\02-2.2384.hdf5\n",
      "2000/2000 [==============================] - 248s 124ms/step - loss: 2.0386 - accuracy: 0.4165 - val_loss: 2.2384 - val_accuracy: 0.3851\n",
      "Epoch 3/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.6873 - accuracy: 0.5247\n",
      "Epoch 3: val_loss improved from 2.23843 to 2.08335, saving model to ./model\\03-2.0834.hdf5\n",
      "2000/2000 [==============================] - 221s 110ms/step - loss: 1.6873 - accuracy: 0.5247 - val_loss: 2.0834 - val_accuracy: 0.4334\n",
      "Epoch 4/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.4603 - accuracy: 0.5896\n",
      "Epoch 4: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 217s 109ms/step - loss: 1.4603 - accuracy: 0.5896 - val_loss: 2.2698 - val_accuracy: 0.4294\n",
      "Epoch 5/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.2819 - accuracy: 0.6437\n",
      "Epoch 5: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 219s 110ms/step - loss: 1.2819 - accuracy: 0.6437 - val_loss: 2.6614 - val_accuracy: 0.4521\n",
      "Epoch 6/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.1537 - accuracy: 0.6829\n",
      "Epoch 6: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 219s 110ms/step - loss: 1.1537 - accuracy: 0.6829 - val_loss: 2.4026 - val_accuracy: 0.4737\n",
      "Epoch 7/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.0782 - accuracy: 0.7082\n",
      "Epoch 7: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 216s 108ms/step - loss: 1.0782 - accuracy: 0.7082 - val_loss: 2.9872 - val_accuracy: 0.4347\n",
      "Epoch 8/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.0158 - accuracy: 0.7281\n",
      "Epoch 8: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 220s 110ms/step - loss: 1.0158 - accuracy: 0.7281 - val_loss: 2.8096 - val_accuracy: 0.4113\n",
      "Epoch 9/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.9624 - accuracy: 0.7489\n",
      "Epoch 9: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 213s 107ms/step - loss: 0.9624 - accuracy: 0.7489 - val_loss: 3.6343 - val_accuracy: 0.4230\n",
      "Epoch 10/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.9276 - accuracy: 0.7619\n",
      "Epoch 10: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 215s 107ms/step - loss: 0.9276 - accuracy: 0.7619 - val_loss: 3.7682 - val_accuracy: 0.4429\n",
      "Epoch 11/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.8911 - accuracy: 0.7744\n",
      "Epoch 11: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 219s 109ms/step - loss: 0.8911 - accuracy: 0.7744 - val_loss: 3.4087 - val_accuracy: 0.4232\n",
      "Epoch 12/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.9059 - accuracy: 0.7765\n",
      "Epoch 12: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 219s 110ms/step - loss: 0.9059 - accuracy: 0.7765 - val_loss: 3.2971 - val_accuracy: 0.3296\n",
      "Epoch 13/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.8532 - accuracy: 0.7931\n",
      "Epoch 13: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 206s 103ms/step - loss: 0.8532 - accuracy: 0.7931 - val_loss: 5.2226 - val_accuracy: 0.4053\n",
      "Epoch 14/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.8812 - accuracy: 0.7956\n",
      "Epoch 14: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 221s 111ms/step - loss: 0.8812 - accuracy: 0.7956 - val_loss: 5.2487 - val_accuracy: 0.3654\n",
      "Epoch 15/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.9081 - accuracy: 0.7975\n",
      "Epoch 15: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 216s 108ms/step - loss: 0.9081 - accuracy: 0.7975 - val_loss: 3.5731 - val_accuracy: 0.3408\n",
      "Epoch 16/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.9099 - accuracy: 0.7987\n",
      "Epoch 16: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 227s 113ms/step - loss: 0.9099 - accuracy: 0.7987 - val_loss: 5.6455 - val_accuracy: 0.4454\n",
      "Epoch 17/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.9380 - accuracy: 0.7965\n",
      "Epoch 17: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 224s 112ms/step - loss: 0.9380 - accuracy: 0.7965 - val_loss: 5.1674 - val_accuracy: 0.4185\n",
      "Epoch 18/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.9576 - accuracy: 0.7989\n",
      "Epoch 18: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 208s 104ms/step - loss: 0.9576 - accuracy: 0.7989 - val_loss: 5.4298 - val_accuracy: 0.3794\n",
      "Epoch 19/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.9646 - accuracy: 0.8013\n",
      "Epoch 19: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 220s 110ms/step - loss: 0.9646 - accuracy: 0.8013 - val_loss: 6.0053 - val_accuracy: 0.4155\n",
      "Epoch 20/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.0298 - accuracy: 0.8005\n",
      "Epoch 20: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 226s 113ms/step - loss: 1.0298 - accuracy: 0.8005 - val_loss: 4.5283 - val_accuracy: 0.3567\n",
      "Epoch 21/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.0158 - accuracy: 0.8028\n",
      "Epoch 21: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 205s 103ms/step - loss: 1.0158 - accuracy: 0.8028 - val_loss: 6.1502 - val_accuracy: 0.4140\n",
      "Epoch 22/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.0309 - accuracy: 0.8067\n",
      "Epoch 22: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 210s 105ms/step - loss: 1.0309 - accuracy: 0.8067 - val_loss: 7.1368 - val_accuracy: 0.3996\n",
      "Epoch 23/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.0435 - accuracy: 0.8062\n",
      "Epoch 23: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 205s 103ms/step - loss: 1.0435 - accuracy: 0.8062 - val_loss: 11.0518 - val_accuracy: 0.4608\n",
      "Epoch 24/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.1067 - accuracy: 0.8057\n",
      "Epoch 24: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 209s 104ms/step - loss: 1.1067 - accuracy: 0.8057 - val_loss: 8.0179 - val_accuracy: 0.3923\n",
      "Epoch 25/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.1466 - accuracy: 0.8020\n",
      "Epoch 25: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 231s 115ms/step - loss: 1.1466 - accuracy: 0.8020 - val_loss: 8.5887 - val_accuracy: 0.3762\n",
      "Epoch 26/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.1443 - accuracy: 0.8038\n",
      "Epoch 26: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 228s 114ms/step - loss: 1.1443 - accuracy: 0.8038 - val_loss: 7.1593 - val_accuracy: 0.3956\n",
      "Epoch 27/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.2359 - accuracy: 0.8045\n",
      "Epoch 27: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 218s 109ms/step - loss: 1.2359 - accuracy: 0.8045 - val_loss: 8.9809 - val_accuracy: 0.3542\n",
      "Epoch 28/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.2397 - accuracy: 0.7942\n",
      "Epoch 28: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 201s 100ms/step - loss: 1.2397 - accuracy: 0.7942 - val_loss: 7.1094 - val_accuracy: 0.3978\n",
      "Epoch 29/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.2875 - accuracy: 0.7915\n",
      "Epoch 29: val_loss did not improve from 2.08335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 195s 98ms/step - loss: 1.2875 - accuracy: 0.7915 - val_loss: 14.4826 - val_accuracy: 0.3752\n",
      "Epoch 30/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.2414 - accuracy: 0.7992\n",
      "Epoch 30: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 181s 91ms/step - loss: 1.2414 - accuracy: 0.7992 - val_loss: 7.6322 - val_accuracy: 0.3849\n",
      "Epoch 31/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.2302 - accuracy: 0.7944\n",
      "Epoch 31: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 177s 89ms/step - loss: 1.2302 - accuracy: 0.7944 - val_loss: 14.1981 - val_accuracy: 0.3943\n",
      "Epoch 32/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.2969 - accuracy: 0.7909\n",
      "Epoch 32: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 186s 93ms/step - loss: 1.2969 - accuracy: 0.7909 - val_loss: 9.8451 - val_accuracy: 0.4035\n",
      "Epoch 33/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.3216 - accuracy: 0.7972\n",
      "Epoch 33: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 197s 99ms/step - loss: 1.3216 - accuracy: 0.7972 - val_loss: 15.3711 - val_accuracy: 0.3988\n",
      "Epoch 34/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.2942 - accuracy: 0.8025\n",
      "Epoch 34: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 202s 101ms/step - loss: 1.2942 - accuracy: 0.8025 - val_loss: 9.6474 - val_accuracy: 0.3747\n",
      "Epoch 35/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.3506 - accuracy: 0.7974\n",
      "Epoch 35: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 204s 102ms/step - loss: 1.3506 - accuracy: 0.7974 - val_loss: 21.3390 - val_accuracy: 0.4003\n",
      "Epoch 36/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.3170 - accuracy: 0.8091\n",
      "Epoch 36: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 221s 111ms/step - loss: 1.3170 - accuracy: 0.8091 - val_loss: 10.9027 - val_accuracy: 0.4020\n",
      "Epoch 37/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.3745 - accuracy: 0.8080\n",
      "Epoch 37: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 229s 114ms/step - loss: 1.3745 - accuracy: 0.8080 - val_loss: 6.8408 - val_accuracy: 0.3577\n",
      "Epoch 38/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.3383 - accuracy: 0.8118\n",
      "Epoch 38: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 241s 120ms/step - loss: 1.3383 - accuracy: 0.8118 - val_loss: 9.9469 - val_accuracy: 0.3781\n",
      "Epoch 39/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.3399 - accuracy: 0.8194\n",
      "Epoch 39: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 209s 105ms/step - loss: 1.3399 - accuracy: 0.8194 - val_loss: 10.8625 - val_accuracy: 0.3978\n",
      "Epoch 40/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.3174 - accuracy: 0.8251\n",
      "Epoch 40: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 200s 100ms/step - loss: 1.3174 - accuracy: 0.8251 - val_loss: 10.0723 - val_accuracy: 0.3881\n",
      "Epoch 41/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.3803 - accuracy: 0.8192\n",
      "Epoch 41: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 198s 99ms/step - loss: 1.3803 - accuracy: 0.8192 - val_loss: 14.1956 - val_accuracy: 0.3530\n",
      "Epoch 42/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.2992 - accuracy: 0.8263\n",
      "Epoch 42: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 195s 97ms/step - loss: 1.2992 - accuracy: 0.8263 - val_loss: 10.5604 - val_accuracy: 0.3869\n",
      "Epoch 43/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.3861 - accuracy: 0.8231\n",
      "Epoch 43: val_loss did not improve from 2.08335\n",
      "2000/2000 [==============================] - 192s 96ms/step - loss: 1.3861 - accuracy: 0.8231 - val_loss: 14.7254 - val_accuracy: 0.3981\n",
      "Epoch 44/100\n",
      " 633/2000 [========>.....................] - ETA: 1:54 - loss: 1.3350 - accuracy: 0.8259"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                   validation_data = validation_generator,\n",
    "                   epochs = 100\n",
    "                   ,callbacks = [early_stopping_clbk, checkpointer])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2036779d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 37s 185ms/step - loss: 2.4185 - accuracy: 0.3796\n",
      "Test Accuracy: 0.3796180486679077\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (100,) and (18,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTraining Accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs_range, val_acc, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\pyplot.py:3578\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3570\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   3571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[0;32m   3572\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3576\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3577\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[1;32m-> 3578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[0;32m   3579\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m   3580\u001b[0m         scalex\u001b[38;5;241m=\u001b[39mscalex,\n\u001b[0;32m   3581\u001b[0m         scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[0;32m   3582\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m   3583\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3584\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1721\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1479\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1480\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1718\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1720\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1721\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1722\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1723\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\axes\\_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    301\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    302\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 303\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\tf\\lib\\site-packages\\matplotlib\\axes\\_base.py:499\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    496\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    500\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    503\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (100,) and (18,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 평가\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f'Test Accuracy: {test_acc}')\n",
    "\n",
    "# 학습 곡선 그리기\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(1, epochs+1)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c609313e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
